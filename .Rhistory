index <- sample(2, nrow(Pred_PFC_SC), replace = TRUE,prob = c(0.7,0.3))
Training <- Pred_PFC_SC[index ==1,]
Testing <- Pred_PFC_SC[index ==2,]
# training the model by assigning Currency Crisis column
# as target variable and rest other column
# as independent variable
set.seed(12345)
RFM <- randomForest(SystemicCrises ~., data = Training)
RFM
# Run model on test set
set.seed(5678)
SystCrisis_Pred <- predict(RFM,Testing)
Testing$SystCrisis_Pred <- SystCrisis_Pred
# Create Confusion Matrix to asses model
Conf_SystCrisis <- table(Testing$SystCrisis_Pred,Testing$SystemicCrises,  dnn=c("Predicted", "Actual"))
Conf_SystCrisis
Accuracy_SystCrisis <- sum(diag(Conf_SystCrisis)/sum(Conf_SystCrisis))
Accuracy_SystCrisis
Model <- "DiagRF1_SC"
Crises <- "Systemic"
Preds_used <- "NO"
Feat_Sel <- "NO"
Accuracy <- Accuracy_SystCrisis
Precision <- precision(Conf_SystCrisis)
Recall <- recall(Conf_SystCrisis)
Sensitivity <- sensitivity(Conf_SystCrisis)
Specificity <- specificity(Conf_SystCrisis)
F1 <- F_meas(Conf_SystCrisis)
DiagRF1_SC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
# INFLATION CRISIS PREDICTION
# Use only Inflation crises as predictor, remove other predictors
colnames(Pred_PFC)
Pred_PFC_IC <-Pred_PFC[,-c(19,20,21)]
str(Pred_PFC_IC)
# Create train and test Data sets
index <- sample(2, nrow(Pred_PFC_IC), replace = TRUE,prob = c(0.7,0.3))
Training <- Pred_PFC_IC[index ==1,]
Testing <- Pred_PFC_IC[index ==2,]
# training the model by assigning Currency Crisis column
# as target variable and rest other column
# as independent variable
set.seed(12345)
RFM <- randomForest(InflationCrises ~., data = Training)
RFM
# Run model on test set
set.seed(5678)
InflCrisis_Pred <- predict(RFM,Testing)
Testing$InflCrisis_Pred <- InflCrisis_Pred
# Create Confusion Matrix to asses model
Conf_InflCrisis <- table(Testing$InflCrisis_Pred, Testing$InflationCrises,  dnn=c("Predicted", "Actual"))
Conf_InflCrisis
Accuracy_InflCrisis <- sum(diag(Conf_InflCrisis)/sum(Conf_InflCrisis))
Accuracy_InflCrisis
Model <- "DiagRF1_IC"
Crises <- "Inflation"
Preds_used <- "NO"
Feat_Sel <- "NO"
Accuracy <- Accuracy_InflCrisis
Precision <- precision(Conf_InflCrisis)
Recall <- recall(Conf_InflCrisis)
Sensitivity <- sensitivity(Conf_InflCrisis)
Specificity <- specificity(Conf_InflCrisis)
F1 <- F_meas(Conf_InflCrisis)
DiagRF1_IC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
All_DiagRF1 <- rbind(DiagRF1_BC,DiagRF1_CC, DiagRF1_SC,DiagRF1_IC)
#####
# Simplify Random Forest Modelling and use predictors as independent variables
# Create train and test Data sets
index <- sample(2, nrow(Pred_PFC), replace = TRUE,prob = c(0.7,0.3))
Training <- Pred_PFC[index ==1,]
Testing <- Pred_PFC[index ==2,]
## BANKING CRISES ##
# training the model by assigning Currency Crisis column
# as target variable and other columns
# as independent variable
set.seed(12345)
RFMBC <- randomForest(BankingCrises ~., data = Training)
RFMBC
# Run model on test set
set.seed(5678)
BC_Pred <- predict(RFMBC,Testing)
Testing$BC_Pred <- BC_Pred
# Create Confusion Matrix to asses model
Conf_BC <- table(Testing$BC_Pred, Testing$BankingCrises,  dnn=c("Predicted", "Actual"))
Conf_BC
Accuracy_BC <- sum(diag(Conf_BC)/sum(Conf_BC))
Accuracy_BC
Model <- "DiagRF2_BC"
Crises <- "Banking"
Preds_used <- "YES"
Feat_Sel <- "NO"
Accuracy <- Accuracy_BC
Precision <- precision(Conf_BC)
Recall <- recall(Conf_BC)
Sensitivity <- sensitivity(Conf_BC)
Specificity <- specificity(Conf_BC)
F1 <- F_meas(Conf_BC)
DiagRF2_BC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## CURRENCY CRISES ##
# training the model by assigning Currency Crisis column
# as target variable and other columns
# as independent variable
set.seed(12345)
RFMCC <- randomForest(CurrencyCrises ~., data = Training)
RFMCC
# Run model on test set
set.seed(5678)
CC_Pred <- predict(RFMCC,Testing)
Testing$CC_Pred <- CC_Pred
# Create Confusion Matrix to asses model
Conf_CC <- table(Testing$CC_Pred, Testing$CurrencyCrises,  dnn=c("Predicted","Actual"))
Conf_CC
Accuracy_CC <- sum(diag(Conf_CC)/sum(Conf_CC))
Model <- "DiagRF2_CC"
Crises <- "Currency"
Preds_used <- "YES"
Feat_Sel <- "NO"
Accuracy <- Accuracy_CC
Precision <- precision(Conf_CC)
Recall <- recall(Conf_CC)
Sensitivity <- sensitivity(Conf_CC)
Specificity <- specificity(Conf_CC)
F1 <- F_meas(Conf_CC)
DiagRF2_CC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1,Model)
## SYSTEMIC CRISES ##
# training the model by assigning Systemic Crisis column
# as target variable and other columns
# as independent variable
set.seed(12345)
RFMSC <- randomForest(SystemicCrises ~., data = Training)
RFMSC
# Run model on test set
set.seed(5678)
SC_Pred <- predict(RFMSC,Testing)
Testing$SC_Pred <- SC_Pred
# Create Confusion Matrix to asses model
Conf_SC <- table(Testing$SC_Pred, Testing$SystemicCrises,  dnn=c("Predicted","Actual"))
Conf_SC
Accuracy_SC <- sum(diag(Conf_SC)/sum(Conf_SC))
Accuracy_SC
Model <- "DiagRF2_SC"
Crises <- "Systemic"
Preds_used <- "YES"
Feat_Sel <- "NO"
Accuracy <- Accuracy_SC
Precision <- precision(Conf_SC)
Recall <- recall(Conf_SC)
Sensitivity <- sensitivity(Conf_SC)
Specificity <- specificity(Conf_SC)
F1 <- F_meas(Conf_SC)
DiagRF2_SC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## INFLATION CRISES ##
# training the model by assigning Inflation Crisis column
# as target variable and other columns
# as independent variable
set.seed(12345)
RFMIC <- randomForest(InflationCrises ~., data = Training)
RFMIC
# Run model on test set
set.seed(5678)
IC_Pred <- predict(RFMIC,Testing)
Testing$IC_Pred <- IC_Pred
# Create Confusion Matrix to asses model
Conf_IC <- table(Testing$IC_Pred, Testing$InflationCrises,dnn=c("Predicted","Actual") )
Conf_IC
Accuracy_IC <- sum(diag(Conf_IC)/sum(Conf_IC))
Accuracy_IC
Model <- "DiagRF2_IC"
Crises <- "Inflation"
Preds_used <- "YES"
Feat_Sel <- "NO"
Accuracy <- Accuracy_IC
Precision <- precision(Conf_IC)
Recall <- recall(Conf_IC)
Sensitivity <- sensitivity(Conf_IC)
Specificity <- specificity(Conf_IC)
F1 <- F_meas(Conf_IC)
DiagRF2_IC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
# Random Forest Diagnostics #
DiagRF_ALL <- rbind(DiagRF1_BC,DiagRF1_CC, DiagRF1_SC, DiagRF1_IC, DiagRF2_BC,DiagRF2_CC, DiagRF2_SC, DiagRF2_IC)
#####
# Using the above model with predictors included as Independent variables, now only the top 5 and top 7 most important
# independent variables will be used to train the model.
## BANKING CRISES Top 5 and 7 variables ##
# training the model by assigning Currency Crisis column
# as target variable and other columns
# as independent variable
varImp_RFMBC <- print(varImp(RFMBC))
### These are the top 7 important variables  ###
# SystemicCrises
# 89.697040
# GDPconpPerch
# 30.860586
# GDPconpPCPPPidUnits
# 19.191831
# TotalInv
# 13.823279
# INFcpi
# 13.582253
# GrossNatSavs
# 13.571722
# GDPdefIndex
# 13.330070
colnames(Training)
colnames(Testing)
# Use only top 5 Important variables
set.seed(12345)
RFMBCFS5 <- randomForest(BankingCrises ~., data = Training[,c(20,7,6,16,14,19)])
RFMBCFS5
# Run model on test set
set.seed(5678)
BC_PredFS5 <- predict(RFMBCFS5,Testing[,c(20,7,6,16,14,19)])
Testing$BC_PredFS5 <- BC_PredFS5
# Create Confusion Matrix to asses model
Conf_BCFS5 <- table(Testing$BC_PredFS5, Testing$BankingCrises,  dnn=c("Predicted", "Actual"))
Conf_BCFS5
Accuracy_BCFS5 <- sum(diag(Conf_BCFS5)/sum(Conf_BCFS5))
Accuracy_BCFS5
Model <- "DiagRF2_BCFS5"
Crises <- "Banking"
Preds_used <- "YES"
Feat_Sel <- "Yes  5"
Accuracy <- Accuracy_BCFS5
Precision <- precision(Conf_BCFS5)
Recall <- recall(Conf_BCFS5)
Sensitivity <- sensitivity(Conf_BCFS5)
Specificity <- specificity(Conf_BCFS5)
F1 <- F_meas(Conf_BCFS5)
DiagRF2_BCFS5 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## Use only top 7 Important variables
set.seed(12345)
RFMBCFS7 <- randomForest(BankingCrises ~., data = Training[,c(20,7,6,16,14,11,13,19)])
RFMBCFS7
# Run model on test set
set.seed(5678)
BC_PredFS7 <- predict(RFMBCFS7,Testing[,c(20,7,6,16,14,11,13,19)])
Testing$BC_PredFS7 <- BC_PredFS7
# Create Confusion Matrix to asses model
Conf_BCFS7 <- table(Testing$BC_PredFS7, Testing$BankingCrises,  dnn=c("Predicted", "Actual"))
Conf_BCFS7
Accuracy_BCFS7 <- sum(diag(Conf_BCFS7)/sum(Conf_BCFS7))
Accuracy_BCFS7
Model <- "DiagRF2_BCFS7"
Crises <- "Banking"
Preds_used <- "YES"
Feat_Sel <- "Yes  7"
Accuracy <- Accuracy_BCFS7
Precision <- precision(Conf_BCFS7)
Recall <- recall(Conf_BCFS7)
Sensitivity <- sensitivity(Conf_BCFS7)
Specificity <- specificity(Conf_BCFS7)
F1 <- F_meas(Conf_BCFS7)
DiagRF2_BCFS7 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
DiagRF2_BCFS57 <- rbind(DiagRF1_BC, DiagRF2_BC, DiagRF2_BCFS5,DiagRF2_BCFS7)
## CURRENCY CRISES Top 5 and 7 variable*##
# training the model by assigning Currency Crisis column
# as target variable and other columns
# as independent variable
varImp_RFMCC <- print(varImp(RFMCC))
### These are the top 7 important variables  ###
# INFcpi
# 24.191093
# GDPdefIndex
# 21.474901
# InflationCrises
# 15.520173
# CurrAccUSDBil
# 14.294438
# GDPcurpPCNCUnits
# 14.227269
# GDPconpPerch
# 13.814647
# GDPconpPCNCUnits
# 13.261983
colnames(Training)
colnames(Testing)
# Use only top 5 Important variables
set.seed(12345)
RFMCCFS5 <- randomForest(CurrencyCrises ~., data = Training[,c(21,14,11,22,3,9)])
RFMCCFS5
# Run model on test set
set.seed(5678)
CC_PredFS5 <- predict(RFMCCFS5,Testing[,c(21,14,11,22,3,9)])
Testing$CC_PredFS5 <- CC_PredFS5
# Create Confusion Matrix to asses model
Conf_CCFS5 <- table(Testing$CC_PredFS5, Testing$CurrencyCrises,  dnn=c("Predicted", "Actual"))
Conf_CCFS5
Accuracy_CCFS5 <- sum(diag(Conf_CCFS5)/sum(Conf_CCFS5))
Accuracy_CCFS5
Model <- "DiagRF2_CCFS5"
Crises <- "Currency"
Preds_used <- "YES"
Feat_Sel <- "Yes  5"
Accuracy <- Accuracy_CCFS5
Precision <- precision(Conf_CCFS5)
Recall <- recall(Conf_CCFS5)
Sensitivity <- sensitivity(Conf_CCFS5)
Specificity <- specificity(Conf_CCFS5)
F1 <- F_meas(Conf_CCFS5)
DiagRF2_CCFS5 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## Use only top 7 Important variables
set.seed(12345)
RFMCCFS7 <- randomForest(CurrencyCrises ~., data = Training[,c(21,14,11,22,3,9,7,5)])
RFMCCFS7
# Run model on test set
set.seed(5678)
CC_PredFS7 <- predict(RFMCCFS7,Testing[,c(21,14,11,22,3,9,7,5)])
Testing$CC_PredFS7 <- CC_PredFS7
# Create Confusion Matrix to asses model
Conf_CCFS7 <- table(Testing$CC_PredFS7, Testing$CurrencyCrises,  dnn=c("Predicted", "Actual"))
Conf_CCFS7
Accuracy_CCFS7 <- sum(diag(Conf_CCFS7)/sum(Conf_CCFS7))
Model <- "DiagRF2_CCFS7"
Crises <- "Currency"
Preds_used <- "YES"
Feat_Sel <- "Yes  7"
Accuracy <- Accuracy_CCFS7
Precision <- precision(Conf_CCFS7)
Recall <- recall(Conf_CCFS7)
Sensitivity <- sensitivity(Conf_CCFS7)
Specificity <- specificity(Conf_CCFS7)
F1 <- F_meas(Conf_CCFS7)
DiagRF2_CCFS7 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
DiagRF2_CCFS57 <- rbind(DiagRF1_CC, DiagRF2_CC, DiagRF2_CCFS5,DiagRF2_CCFS7)
## SYSTEMIC CRISES ##
## Top 5 and 7 variable ##
varImp_RFMSC <- print(varImp(RFMSC))
### These are the top 7 important variables  ###
# BankingCrises
# 60.633857
# GDPconpPerch
# 15.744477
# GDPconpPCPPPidUnits
# 11.098262
# INFcpi
# 10.869910
# GDPdefIndex
# 10.552741
# GDPcurpPCNCUnits
# 9.871795
# GDPconpPCNCUnits
# 9.700354
colnames(Training)
colnames(Testing)
# Use only top 5 Important variables
set.seed(12345)
RFMSCFS5 <- randomForest(SystemicCrises ~., data = Training[,c(20,19,7,6,14,11)])
RFMSCFS5
# Run model on test set
set.seed(5678)
SC_PredFS5 <- predict(RFMSCFS5,Testing[,c(20,19,7,6,14,11)])
Testing$SC_PredFS5 <- SC_PredFS5
# Create Confusion Matrix to asses model
Conf_SCFS5 <- table(Testing$SC_PredFS5, Testing$SystemicCrises,  dnn=c("Predicted", "Actual"))
Conf_SCFS5
Accuracy_SCFS5 <- sum(diag(Conf_SCFS5)/sum(Conf_SCFS5))
Model <- "DiagRF2_SCFS5"
Crises <- "Systemic"
Preds_used <- "YES"
Feat_Sel <- "Yes  5"
Accuracy <- Accuracy_SCFS5
Precision <- precision(Conf_SCFS5)
Recall <- recall(Conf_SCFS5)
Sensitivity <- sensitivity(Conf_SCFS5)
Specificity <- specificity(Conf_SCFS5)
F1 <- F_meas(Conf_SCFS5)
DiagRF2_SCFS5 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## Use only top 7 Important variables
set.seed(12345)
RFMSCFS7 <- randomForest(SystemicCrises ~., data = Training[,c(20,19,7,6,14,11,9,5)])
RFMSCFS7
# Run model on test set
set.seed(5678)
SC_PredFS7 <- predict(RFMSCFS7,Testing[,c(20,19,7,6,14,11,9,5)])
Testing$SC_PredFS7 <- SC_PredFS7
# Create Confusion Matrix to asses model
Conf_SCFS7 <- table(Testing$SC_PredFS7, Testing$SystemicCrises,  dnn=c("Predicted", "Actual"))
Conf_SCFS7
Accuracy_SCFS7 <- sum(diag(Conf_SCFS7)/sum(Conf_SCFS7))
Model <- "DiagRF2_SCFS7"
Crises <- "Systemic"
Preds_used <- "YES"
Feat_Sel <- "Yes  7"
Accuracy <- Accuracy_SCFS7
Precision <- precision(Conf_SCFS7)
Recall <- recall(Conf_CCFS7)
Sensitivity <- sensitivity(Conf_SCFS7)
Specificity <- specificity(Conf_SCFS7)
F1 <- F_meas(Conf_SCFS7)
DiagRF2_SCFS7 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
DiagRF2_SCFS57 <- rbind(DiagRF1_SC, DiagRF2_SC, DiagRF2_SCFS5,DiagRF2_SCFS7)
## INFLATION CRISES ##
## Top 5 and 7 variable ##
varImp_RFMIC <- print(varImp(RFMIC))
### These are the top 7 important variables  ###
# INFcpi
# 27.0939789
# GDPdefIndex
# 23.1670611
# GDPcurpPCNCUnits
# 10.8942274
# GDPcurpNCBil
# 9.3525912
# GDPconpPCPPPidUnits
# 8.2583025
# CurrencyCrises
# 8.0917822
# GDPconpPCNCUnits
# 7.2063882
colnames(Training)
colnames(Testing)
# Use only top 5 Important variables
set.seed(12345)
RFMICFS5 <- randomForest(InflationCrises ~., data = Training[,c(22,14,11,9,8,6)])
RFMICFS5
# Run model on test set
set.seed(5678)
IC_PredFS5 <- predict(RFMICFS5,Testing[,c(22,14,11,9,8,6)])
Testing$IC_PredFS5 <- IC_PredFS5
# Create Confusion Matrix to asses model
Conf_ICFS5 <- table(Testing$IC_PredFS5, Testing$InflationCrises,  dnn=c("Predicted", "Actual"))
Conf_ICFS5
Accuracy_ICFS5 <- sum(diag(Conf_ICFS5)/sum(Conf_ICFS5))
Model <- "DiagRF2_ICFS5"
Crises <- "Inflation"
Preds_used <- "YES"
Feat_Sel <- "Yes  5"
Accuracy <- Accuracy_ICFS5
Precision <- precision(Conf_ICFS5)
Recall <- recall(Conf_ICFS5)
Sensitivity <- sensitivity(Conf_ICFS5)
Specificity <- specificity(Conf_ICFS5)
F1 <- F_meas(Conf_ICFS5)
DiagRF2_ICFS5 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
## Use only top 7 Important variables
set.seed(12345)
RFMICFS7 <- randomForest(InflationCrises ~., data = Training[,c(22,14,11,9,8,6,21,5)])
RFMICFS7
# Run model on test set
set.seed(5678)
IC_PredFS7 <- predict(RFMICFS7,Testing[,c(22,14,11,9,8,6,21,5)])
Testing$IC_PredFS7 <- IC_PredFS7
# Create Confusion Matrix to asses model
Conf_ICFS7 <- table(Testing$IC_PredFS7, Testing$InflationCrises,  dnn=c("Predicted", "Actual"))
Conf_ICFS7
Accuracy_ICFS7 <- sum(diag(Conf_ICFS7)/sum(Conf_ICFS7))
Model <- "DiagRF2_ICFS7"
Crises <- "Inflation"
Preds_used <- "YES"
Feat_Sel <- "Yes  7"
Accuracy <- Accuracy_ICFS7
Precision <- precision(Conf_ICFS7)
Recall <- recall(Conf_ICFS7)
Sensitivity <- sensitivity(Conf_ICFS7)
Specificity <- specificity(Conf_ICFS7)
F1 <- F_meas(Conf_ICFS7)
DiagRF2_ICFS7 <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
DiagRF2_ICFS57 <- rbind(DiagRF1_IC, DiagRF2_IC, DiagRF2_ICFS5,DiagRF2_ICFS7)
Diag_ALLRF <- rbind(DiagRF2_BCFS57, DiagRF2_CCFS57, DiagRF2_SCFS57, DiagRF2_ICFS57)
View(Diag_ALLRF)
View(Diag_ALLRF)
View(Training)
Logmod_BC <- glm(BankingCrises ~., family="binomial", data=Training)
#disable scientific notation for model summary
options(scipen=999)
#view model summary
summary(Logmod_BC)
MFR <- pscl::pR2(Logmod_BC)["McFadden"]
VarimpLogmod <- caret::varImp(Logmod_BC)
View(VarimpLogmod)
summary(Logmod_BC)
response <- factor(response,levels=c(level2,level1))
glm.probs <- predict(Logmod_BC,type = "response")
glm.probs[1:10]
exp(coefficients(Logmod_BC))
MFR
View(MFR)
print(MFR)
View(Testing)
# Use model on Testing set
Pred_Logmod_BC <- predict(Logmod_BC, Testing)
Testing$BC_LogmodPred <- Pred_Logmod_BC
summary(Testing$BC_LogmodPred)
hist(Testing$BankCrisis_Pred)
hist(Testing$BC_LogmodPred)
View(Testing)
Testing$BC_Logpred <- ifelse(Testing$BC_LogmodPred <= 0, "NO", "YES")
Testing$BC_Logpred <- as.factor(Testing$BC_Logpred)
View(Testing)
Conf_BC <- table(Testing$BankingCrises, Testing$BC_Logpred)
Conf_BC
Accuracy_BC <- sum(diag(Conf_BC)/sum(Conf_BC))
Accuracy_BC
View(Diag_ALLRF)
check_regression(Logmod_BC,extra=FALSE,tests=TRUE,simulations=500,n.cats=10,seed=NA,prompt=TRUE)
View(Testing)
Conf_BC
Precision <- precision(Conf_BC)
Model <- "Logmod_BC"
Crises <- "Banking"
Preds_used <- "YES"
Feat_Sel <- "NO"
Accuracy <- Accuracy_BC
Precision <- precision(Conf_BC)
Recall <- recall(Conf_BC)
Sensitivity <- sensitivity(Conf_BC)
Specificity <- specificity(Conf_BC)
F1 <- F_meas(Conf_BC)
LogReg_BC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
View(LogReg_BC)
View(Diag_ALLRF)
LogReg2_BC <- data.frame(Crises, Preds_used, Feat_Sel, Accuracy, Precision, Recall, Sensitivity,Specificity, F1, Model)
